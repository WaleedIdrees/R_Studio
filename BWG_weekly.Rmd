---
title: "Cash Deman Forecast App"
output: github_document
---


The code is a script in R programming language that is used to forecast the cash demand for ATM machines. It starts by loading the required libraries which include  tidyverse, lubridate, fpp3, fable, feasts, tsibble, tsibbledata, timeDate, stats, anomaly, anomalize, and furrr.

# CONNCETING TO SQL SERVER AND ALL STEPS
```{r, include=FALSE}
#rm(list = ls())

library(odbc)
library(pool)
library(tidyverse)
library(lubridate)
library(fpp3)
library(fable)
library(feasts)
library(tsibble)
library(tsibbledata)
library(prophet)
library(fable.prophet)
library(timeDate)
library(stats)
library(anomaly)
library(anomalize)
library(readxl)
#library(future.apply)
library(furrr)
plan(multisession, workers = 8)


```


#Intoduction: 


Next, the code fills any gaps in the time series data using the fill_gaps function from the tsibble package. The code also adds year, month, and day columns to the tsibble. The missing values in the data are then replaced with regression (TSLM) values using the interpolate function.

The final part of the code deals with identifying and removing anomalies in the data. It creates a function, named anomoly_function, that finds anomalies in the data for each ATM. The function is then applied to all ATMs using the map_df function. The resulting data frame with anomalous values is named anomolies_values.

Finally, the code uses the ARIMA to fit a time series model to the data. The resulting model is used to forecast the future cash demand for each ATM.



# Load Data

# In this note book we Forecast cash Demand for ATM machines. We have the data for ATM machines from 01-01-2017 to 24-02-2019. the cash deman column is represented by withdrawals. We see the summary of the data below we have 17 missing values in withdrawals Column. 

```{r}
df<- readRDS("cash_demand.rds") 
summary(df)
```

```{r}
summary(is.na(df))

df$TransDate <- 
  as.Date(df$TransDate)
```
# Preprocessing

To forcast r we need to transform our dataframe to tsibble format which id time series data format in r for formcasting. We use TransDate column and date index and the key column as the Groups or categories that we want to forecast. 

```{r}
df<-
df %>% 
    as.data.frame() %>%
  group_by(TransDate) %>%
  summarise(withdrawals = sum(withdrawals)) %>%
  tsibble(index = TransDate)



frcst_tsbl<- 
  df %>% 
  dplyr::select( 
    TransDate, withdrawals
    ) %>% 
  as_tsibble(index=TransDate)

```



# check if the time series is complete and fill the missing dates in the dataframe. Fill_gaps feature makes it easy to find out the if there is any missing date index and it fill those gaps with NA values.

```{r}
#If any data for specific dates is missing, it will produce a date for it and then produce an NA value for that date.

frcst_fill_gaps<-
  fill_gaps(frcst_tsbl, .full=FALSE)

frcst_fill_gaps %>% summary()

```
# Next, we fill any gaps in the time series data using the fill_gaps function from the tsibble package. The code also adds year, month, and day columns to the tsibble. The missing values in the data are then replaced with regression (TSLM) values using the interpolate function.

```{r}
# we need to take care of NA values in data using interpolate function in R.
# instead of mean or median we use TSLM (regression) values to replace NA values.
atms_for_forecast <- 
  frcst_fill_gaps %>% 
  model(lm= TSLM(withdrawals~ trend())) %>%
  #model(arima= ARIMA(withdrawals, stepwise = FALSE)) %>% 
  interpolate(frcst_fill_gaps)


```




```{r}
final_data <-atms_for_forecast
  # atms_for_forecast %>% as.data.frame() %>%
  # group_by(TransDate) %>%
  # summarise(withdrawals = sum(withdrawals)) %>%
  # tsibble(index = TransDate)

```

## group the data by day
```{r}
final_data %>% autoplot()
```
```{r}
final_data %>% 
  mutate(year= year(TransDate),
         month= month(TransDate)) %>% 
  as.data.frame() %>% 
  ggplot()+
  aes(x= TransDate, y=withdrawals, col= factor(month) )+
  geom_line()+
  facet_grid (~ year, scales = "free")
```

```{r}
final_data %>%  
  model(
    STL(log(withdrawals) ~ 
          season(period = "day") +
          season(period = "week")+
          season(period = "month")+
          season(period = "year"),
        robust = TRUE)
  )  %>%
  components() %>%
  autoplot() + labs(x = "Observation")+
  theme(legend.position = "none")
```

Lets perform ADF test to check for stationarity
Adf test 
Null hypothesis: Series is not stationary, 
Alternate hypothesis = Series is stationary
Kpss test 
Null hypothesis: Series is stationary, 
Alternate hypothesis = Series is not stationary
```{r}
library(tseries)
adf.test(final_data$withdrawals); kpss.test(final_data$withdrawals, null="Trend")

```
Adf test test is significant at 0.05% significance level and we can reject null hypothesis that series is not stationary and accep that series is stationary.
Kpss test is also significant which says that the we reject null hypothesis that series is stationary and accept that series is non stationary.
Null hypothesis for both of these tests are opp

lets repeat both these tests for stationarity after taking first difference .

```{r}
df_diff<- final_data %>% mutate(diff_with= difference(withdrawals, 1 )) %>% drop_na()
adf.test(df_diff$diff_with); kpss.test(df_diff$diff_with, null="Trend")
```
Now both of our tests show that differenced series is stationary. So this tells us that our series is stationary at first difference.
Lets look at acf and pcg graphs to find out whether our series following an ma or ar process or is it more complex.

```{r}
df_diff  %>% autoplot(diff_with)
```

# Now we will identify if our series follows an ar(p) or ma(q) or arma(p,q) process.
figure above shows steps of identifying whethere a series follows an ar(p) or ma(q) or arma(p,q) process.

```{r}
pacman::p_load(png)

img <- readPNG('arma.png')
# Set the plot window dimensions to 8x6 inches
# Set the plot window dimensions to 8x6 inches
par(pty="s", mar=c(0,0,0,0), mai=c(0,0,0,0), xpd=NA)
par(fig=c(0,1,0,1), new=TRUE)
plot(0:1, 0:1, type="n", xlab="", ylab="", axes=FALSE)
rasterImage(img, 0, 0, 1, 1)
```
We do not see a sudden decay in ACF plot so our series is not an MA(q) process but we do detect repeated constant significance lags at lag7 which indicates that our series has weekly seasonality.
We dont see a sudden decay in PACF plot either. as we can see significant correlations at lags, 1 to 6.
Our series is an ARMA series. 

```{r}
final_data%>%
  gg_tsdisplay(difference(withdrawals,  1),
               plot_type='partial') +
  labs(title="Seasonally differenced")

```
We will use auto_arima function from the forecast package to identify the best ARMA process and SARIMA process for our series. 


```{r}
# fit an ARIMA model using auto.arima()
fit <-  final_data %>% model(sarima= ARIMA( log(withdrawals)~ 0 + pdq( p= 0:14, d=1, q= 0:14) + PDQ(0,0,0)) )
# print the best ARIMA model
print(fit)
```

```{r}
# fit an ARIMA model using auto.arima()
fit <-  final_data %>% model(sarima= ARIMA( 
  log(withdrawals)~ 0 + pdq( p= 0:14, d=1, q= 0:14) + PDQ(P= 0:10,D=1, Q = 0:14), stepwise = FALSE) )
# print the best ARIMA model
print(fit)
```

Auto arima has picked the model with ARIMA(0,1,2)(4,1,0) with weekly seasonality.

The two graphs below are showing tred in cash demand over 3 years and demand looks very steady. 

```{r}
final_data %>% autoplot()

final_data %>% 
  mutate(year= year(TransDate),
         month= month(TransDate)) %>% 
  as.data.frame() %>% 
  ggplot()+
  aes(x= TransDate, y=withdrawals, col= factor(month) )+
  geom_line()+
  facet_grid (~ year, scales = "free")


```
```{r}
final_data<-
final_data %>%
  mutate(
    Days =day(TransDate),
    Weekday_names = weekdays(TransDate),
    Months =month(TransDate),
    month_end = case_when(
      (Months==12 &Days >= 1) ~ 1,
      TRUE ~ 0)  )
final_data
```



## Test & Train Data
```{r}
data_split<- "2019-11-01"

train_data<-
final_data %>% 
  filter(TransDate < data_split) 
```


ALL DATA IS READY AFTER PREPROCESSING CREATE A MODEL FOR FORECAST
#-3 CREATE MODEL FOR FORECASTING

1 MODEL FOR FORECAST  

```{r}

fit_model <-
  train_data %>%
  model(
    auto_arima = ARIMA(
      log(withdrawals) ,
      stepwise = FALSE
    ),
    dummy_arima = ARIMA(
      log(withdrawals) ~ (Months == 11 & Days > 23) + (Months == 12 &
                                                         Days > 14) +
        (Months == 12 & Days == 24) +
        (Months == 12 & Days == 25) +
        (Months == 12 & Days == 26) +
        (Months == 12 & Days == 27) +
        (Months == 12 & Days == 28) +
        (Months == 12 & Days == 29) +
        (Months == 12 & Days == 30) +
        (Months == 12 & Days == 31),
      stepwise = FALSE
    ),
    sarima = ARIMA(
      log(withdrawals) ~ 0 + pdq(p = 0:5, d = 0:2, q = 0:5) + PDQ(P = 0:5, D = 0:1, Q =
                                                                    0:5),
      stepwise = FALSE
    )
  )
fit_model %>% print()
```
```{r}
augment(fit_model) |>
  features(.innov, ljung_box, dof = 0, lag = 2 )
glance(fit_model)
```


```{r}
#fit_model<- fit_model %>% mutate( average = (auto_arima + sarima) / 2 )
```

## best_model

```{r}
best_model = "dummy_arima"
forecast::checkresiduals(augment(fit_model)%>%
                           filter(.model==best_model)%>%
                           rename(residuals=.resid) %>%
                           mutate(residuals= log(residuals) ) )


```

# Forecast for the next 54
```{r}
year_to= max( final_data$TransDate)
frct_days= as.double(as.Date(year_to)+ days(1) -as.Date(data_split) )

frct_days
```


#### CREATE CODE FOR FORECAST
```{r}

future_xreg <-
  new_data(train_data, n = frct_days) %>%
  mutate(
        Days =day(TransDate),
        Weekday_names = weekdays(TransDate),
        Months =month(TransDate)
     )


# if we already set n in new data, h is not required in forecast as number of forecast days are provided in new_data with n=  option.
frcst_data<- 
fit_model %>% 
    forecast(new_data = future_xreg
             )
frcst_data |>
  autoplot(
    final_data %>%  filter(TransDate >= as.Date(data_split) - days(0))
    ) 

```
```{r}

frcst_data %>% 
  as_data_frame() %>% 
  select(TransDate,.model, .mean) %>% 
  left_join(
    final_data %>%filter(TransDate >= as.Date(data_split) - days(0)) %>% select(TransDate, withdrawals),
          by= "TransDate") %>% 
  mutate(diff= (withdrawals - .mean)^2 ) %>% 
  group_by(.model) %>% 
  summarise(rmse= sqrt( mean(diff) )) %>% 
  arrange(rmse)


```


```{r}
sim_forecast_data<-
fit_model[best_model] %>% 
  generate(new_data = future_xreg, times = 100, bootstrap = TRUE)
```




```{r}
final_data %>%  
  filter(TransDate >= as.Date(data_split) - days(90)) %>% 
  ggplot(aes(x = TransDate)) +
  geom_line(aes(y = withdrawals)) +
  geom_line(data = sim_forecast_data, aes(y = .sim, colour = as.factor(.rep) )) +
  #coord_polar()+
  labs(title="Daily cash demand", y="£GBP" ) +
  guides(col = FALSE)

```


## Aggregated sim forecast
```{r}
sim_forecast_data1<-
sim_forecast_data %>% as.data.frame() %>%  group_by(TransDate) %>% 
  summarise(.sim= mean(.sim)) %>% 
  tsibble(index = TransDate)

```


```{r}
final_data %>%  
  filter(TransDate >= as.Date(data_split) - days(90)) %>% 
  ggplot(aes(x = TransDate)) +
  geom_line(aes(y = withdrawals)) +
  geom_line(aes(y = .sim, colour = "red" ),
    data = sim_forecast_data1) +
  #coord_polar()+
  labs(title="Daily cash demand", y="£GBP" ) +
  guides(col = FALSE)
```


```{r}
set.seed(9)

fit_model[best_model] %>%
  generate(new_data = train_data ,
           times = 100,
            bootstrap= TRUE,
           bootstrap_block_size	= 30
           ) %>%
    #filter(.model == "Arima") %>% 
    autoplot(.sim) +
  autolayer(final_data, withdrawals) +
  guides(colour = "none") +
  labs(title = " Bootstrapped series",
       y="withdrawals ('000)")


```

```{r}
set.seed(13)
sim<-
fit_model[best_model] %>%
  generate(new_data = train_data, 
           times = 50,
           bootstrap = TRUE,
           bootstrap_block_size = 30 
           ) %>% 
  select(-.model) %>% 
  tsibble(
    index = TransDate,
    key= c(.rep) 
    )
```


```{r}
fit_model_sim <-
  sim %>%
  model(
    ARIMA(
      .sim
      )
    )

```

```{r}
frcst_data1<-
  fit_model_sim %>% 
  forecast(h = frct_days) %>% 
  select(-c(.model))
  
df2<-
frcst_data1 %>%
  update_tsibble(key = .rep) %>%
   summarise (bmean= mean(.mean)) %>% 
  tsibble(index = TransDate)

final_data %>%  filter(TransDate >= as.Date(data_split) - days(90)) %>% 
  full_join (df2, by= c("TransDate")) %>% 
ggplot() +
  geom_line(aes(x = TransDate,y = withdrawals), alpha= 1) +
   geom_line(aes(x = TransDate,y = bmean, col= "blue"))+   
  labs(title="Cash Demand", y="£GBP" ) +
   #coord_polar()+
  guides(col = FALSE)
```

